{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain qdrant-client openai pypdf pypdf2 langchain-openai langchain-community uuid tiktoken pikepdf sentence_transformers langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.schema import retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables\n",
    "qdrant_host = os.getenv('QDRANT_HOST')\n",
    "# openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://qdrant-dev.yirifi.ai:443\n"
     ]
    }
   ],
   "source": [
    "print(qdrant_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize qdrant client\n",
    "client = QdrantClient(url=qdrant_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of collections present in qdrant store\n",
    "collections = client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llamaparse pdf file\n",
      "Empathy_Tales\n",
      "RegDb vectors 1000-chars-sb\n",
      "llamaparse pl 256-tokens\n",
      "RegDb Vectors v1\n",
      "RegDb Vectors v2\n",
      "test 768-dim\n",
      "test\n",
      "RegDb Vectors\n",
      "llamaparse 3-pdf files\n",
      "New-768-dim-sb\n"
     ]
    }
   ],
   "source": [
    "# Print list of collections\n",
    "list_of_collections = collections.collections\n",
    "for collection in list_of_collections:\n",
    "  print(collection.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a document store\n",
    "doc_store = Qdrant(\n",
    "        client=client,\n",
    "        collection_name='Empathy_Tales', # Can change the collection here\n",
    "        embeddings = hf\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize openai llm\n",
    "# llm = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\", groq_api_key='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "        llm = llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever= doc_store.as_retriever(),\n",
    "        return_source_documents=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = 'What is the moral of the story of water taking any shape of a container?'\n",
    "response = qa.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What is the moral of the story of water taking any shape of a container?\n",
      "Answer: The moral of the story of water taking any shape of a container is: \"The importance of considering multiple perspectives and conditions before making assumptions or conclusions.\" This story illustrates that there are often factors (like temperature, in this case) that can significantly impact the outcome of a situation, and it's crucial to take these factors into account before drawing conclusions.\n"
     ]
    }
   ],
   "source": [
    "print(f\"User Query: {response['query']}\")\n",
    "print(f\"Answer: {response['result']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
