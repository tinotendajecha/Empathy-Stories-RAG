{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain qdrant-client openai pypdf pypdf2 langchain-openai langchain-community uuid tiktoken pikepdf sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file line by line\n",
    "df = pd.read_csv('EmpathyTales-DB - ETales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stories_and_their_meta_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What i want to basically do is create a list iterate through the whole csv file append content of each row into \n",
    "for index, row in df.iterrows():\n",
    "    # Take the three diff columns\n",
    "    # Create a list for each story\n",
    "    whole_tale_list = []\n",
    "\n",
    "    if not pd.isnull(row['EmpathTale']):\n",
    "        whole_tale_list.append(row['EmpathTale'])\n",
    "    \n",
    "    if not pd.isnull(row['tags']):\n",
    "        whole_tale_list.append(row['tags'])\n",
    "\n",
    "    if not pd.isnull(['tags0']):\n",
    "        whole_tale_list.append(row['tags0'])\n",
    "    \n",
    "\n",
    "    list_of_stories_and_their_meta_data.append(whole_tale_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "cleaned_lists = []\n",
    "for tale in list_of_stories_and_their_meta_data:\n",
    "    cleaned_list = [value for value in tale if not (isinstance(value, float) and math.isnan(value))]\n",
    "    cleaned_lists.append(cleaned_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stories_and_their_meta_data = cleaned_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now iterate through this list and embed every single index - ideal to count tokens first\n",
    "def count_number_of_words(paragraph):\n",
    "    words = paragraph.split()\n",
    "    count = len(words)\n",
    "\n",
    "    return count\n",
    "\n",
    "# for each_story in list_of_stories_and_their_meta_data:\n",
    "#     print(count_number_of_words(each_story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For async function in notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the stories and insert into the vector store\n",
    "from qdrant_client.models import VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import AsyncQdrantClient, models\n",
    "import uuid\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Yirifi Qdrant db!\n"
     ]
    }
   ],
   "source": [
    "# Your async code using QdrantClient might be put here\n",
    "client = AsyncQdrantClient(url=\"https://qdrant-dev.yirifi.ai:443\")\n",
    "print('Connected to Yirifi Qdrant db!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'Empathy_Tales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of all existing collections and append to list\n",
    "info = await client.get_collections()\n",
    "existing_collections = [] # List for appending existing collections in the vector db\n",
    "for each_collection in info.collections:\n",
    "    existing_collections.append(each_collection.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llamaparse pdf file',\n",
       " 'RegDb vectors 1000-chars-sb',\n",
       " 'llamaparse pl 256-tokens',\n",
       " 'RegDb Vectors v1',\n",
       " 'RegDb Vectors v2',\n",
       " 'test 768-dim',\n",
       " 'test',\n",
       " 'RegDb Vectors',\n",
       " 'llamaparse 3-pdf files',\n",
       " 'New-768-dim-sb']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expression returns Boolean value True if collection exists\n",
    "collectionExists = True if collection_name in existing_collections else False\n",
    "collectionExists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Created!\n"
     ]
    }
   ],
   "source": [
    "# If collection does not exist create one using qdrant client\n",
    "if collectionExists == False:\n",
    "  await client.create_collection(\n",
    "  collection_name=collection_name,\n",
    "  vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "  )\n",
    "  print('Collection Created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted vector point $1\n",
      "Inserted vector point $2\n",
      "Inserted vector point $3\n",
      "Inserted vector point $4\n",
      "Inserted vector point $5\n",
      "Inserted vector point $6\n",
      "Inserted vector point $7\n",
      "Inserted vector point $8\n",
      "Inserted vector point $9\n",
      "Inserted vector point $10\n",
      "Inserted vector point $11\n",
      "Inserted vector point $12\n",
      "Inserted vector point $13\n",
      "Inserted vector point $14\n",
      "Inserted vector point $15\n",
      "Inserted vector point $16\n",
      "Inserted vector point $17\n",
      "Inserted vector point $18\n",
      "Inserted vector point $19\n",
      "Inserted vector point $20\n",
      "Inserted vector point $21\n",
      "Inserted vector point $22\n",
      "Inserted vector point $23\n",
      "Inserted vector point $24\n",
      "Inserted vector point $25\n",
      "Inserted vector point $26\n",
      "Inserted vector point $27\n",
      "Inserted vector point $28\n",
      "Inserted vector point $29\n",
      "Inserted vector point $30\n",
      "Inserted vector point $31\n",
      "Inserted vector point $32\n",
      "Inserted vector point $33\n",
      "Inserted vector point $34\n",
      "Inserted vector point $35\n",
      "Inserted vector point $36\n",
      "Inserted vector point $37\n",
      "Inserted vector point $38\n",
      "Inserted vector point $39\n",
      "Inserted vector point $40\n",
      "Inserted vector point $41\n",
      "Inserted vector point $42\n",
      "Inserted vector point $43\n",
      "Inserted vector point $44\n",
      "Inserted vector point $45\n",
      "Inserted vector point $46\n",
      "Inserted vector point $47\n",
      "Inserted vector point $48\n",
      "Inserted vector point $49\n",
      "Inserted vector point $50\n"
     ]
    }
   ],
   "source": [
    "for index, each_story_and_metadata in enumerate(list_of_stories_and_their_meta_data, start=1):\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=768) # Configure dimensions to use\n",
    "\n",
    "    # Create the vector embeddings\n",
    "    embeddings = hf.embed_query(str(each_story_and_metadata))\n",
    "\n",
    "    # create the metadata\n",
    "    meta_data = {\n",
    "        \"page_content\" : str(each_story_and_metadata),\n",
    "    }\n",
    "\n",
    "    unique_id = uuid.uuid4()\n",
    "\n",
    "    vector = {\n",
    "        \"id\" : str(unique_id),\n",
    "        \"vector\": embeddings,\n",
    "        \"payload\" : meta_data\n",
    "    }\n",
    "\n",
    "    await client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points =[\n",
    "            models.PointStruct(\n",
    "                id=vector[\"id\"],\n",
    "                vector=vector[\"vector\"],\n",
    "                payload=vector[\"payload\"]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"Inserted vector point ${index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
